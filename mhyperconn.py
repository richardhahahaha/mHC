# 实现 
# mHC: Manifold-Constrained Hyper-Connections
# https://arxiv.org/abs/2409.19606
# https://arxiv.org/pdf/2512.24880

import torch
import torch.nn as nn
import torch.nn.functional as F
from math import sqrt

def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor

def trunc_normal_(tensor, mean: float = 0., std: float = 1., a: float = -2., b: float = 2.):
    r"""Fills the input Tensor with values drawn from a truncated
    normal distribution. The values are effectively drawn from the
    normal distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`
    with values outside :math:`[a, b]` redrawn until they are within
    the bounds. The method used for generating the random values works
    best when :math:`a \leq \text{mean} \leq b`.

    Args:
        tensor: an n-dimensional `torch.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value

    Examples:
        >>> w = torch.empty(3, 5)
        >>> nn.init.trunc_normal_(w)
    """
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

class SinusoidalPositionEncoding(nn.Module):
    """正弦位置编码，将原始 x,y 坐标编码为高维特征"""
    def __init__(self, d_model, max_len=512):
        super().__init__()
        assert d_model % 2 == 0
        self.d_model = d_model
        # 预计算频率分量
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        self.register_buffer('div_term', div_term)
        self.max_len = max_len
    
    def forward(self, pos):
        """
        pos: (batch, seq_len) 或 (batch, seq_len, 1) - 原始坐标值
        returns: (batch, seq_len, d_model)
        """
        if pos.dim() == 3:
            pos = pos.squeeze(-1)
        # 归一化到 [0, 1] 范围
        pos_normalized = pos / self.max_len
        # 扩展维度: (batch, seq_len, d_model//2)
        pos_expanded = pos_normalized.unsqueeze(-1) * self.div_term * self.max_len
        # 交替 sin/cos
        pe = torch.zeros(*pos.shape, self.d_model, device=pos.device, dtype=pos.dtype)
        pe[..., 0::2] = torch.sin(pos_expanded)
        pe[..., 1::2] = torch.cos(pos_expanded)
        return pe

def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):
    """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).

    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...
    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for
    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use
    'survival rate' as the argument.

    """
    if drop_prob == 0. or not training:
        return x
    keep_prob = 1 - drop_prob
    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets
    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)
    if keep_prob > 0.0 and scale_by_keep:
        random_tensor.div_(keep_prob)
    return x * random_tensor


class DropPath(nn.Module):
    """Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).
    """
    def __init__(self, drop_prob=None, scale_by_keep=True):
        super().__init__()
        self.drop_prob = drop_prob
        self.scale_by_keep = scale_by_keep

    def forward(self, x):
        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)

class RMSNorm(nn.Module):
    def __init__(self, dim: int, eps: float = 1e-6):
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))
    def forward(self, x: torch.Tensor):
        # 计算每个样本的均方根
        norm = (x.pow(2).mean(-1, keepdim=True) + self.eps).rsqrt()
        return x * (self.weight * norm)
    
def sinkhorn_knopp(matrix: torch.Tensor, num_iter: int = 20, epsilon: float = 1e-20) -> torch.Tensor:
    """
    Sinkhorn-Knopp 算法，将矩阵投影至双随机矩阵流形。
    双随机矩阵满足：所有行和为1，所有列和为1，且元素非负。
    
    参数:
        matrix: 输入矩阵，形状为 [batch_size, n, n]
        num_iter: 迭代次数，mHC论文中推荐20次【turn0search2】【turn0search5】
        epsilon: 防止除零的小常数，保证数值稳定性
        
    返回:
        双随机矩阵，形状与输入相同
    """
    # 确保输入矩阵非负（通常先经过指数化）
    # 减去最大值防止 exp 爆炸（Log-Sum-Exp 技巧的变体）
    matrix = torch.nan_to_num(matrix, nan=0.0, posinf=0.0, neginf=0.0)
    matrix = matrix - torch.max(matrix, dim=-1, keepdim=True)[0]
    K = torch.exp(matrix)
    for _ in range(num_iter):
        # 行归一化，使每行和为1
        K = K / (K.sum(dim=-1, keepdim=True) + epsilon)
        # 列归一化，使每列和为1
        K = K / (K.sum(dim=-2, keepdim=True) + epsilon)
    return K

def init_transformer_weights(module: nn.Module) -> None:
    # --- HyperConnection 模块的初始化检查 ---    
    if isinstance(module, HyperConnection):        
        # 确保动态映射的缩放因子保持为论文推荐的小值 (0.01)        
        # 防止被其他初始化逻辑（如 trunc_normal_）错误覆盖        
        if hasattr(module, 'dynamic_alpha_scale'):
            nn.init.constant_(module.dynamic_alpha_scale, 0.01)        
        if hasattr(module, 'dynamic_beta_scale'):
            nn.init.constant_(module.dynamic_beta_scale, 0.01)        
        return
    if isinstance(module, nn.Linear):
        trunc_normal_(module.weight, std=0.02)
        if module.bias is not None:
            nn.init.zeros_(module.bias)
        return

    if isinstance(module, nn.Embedding):
        trunc_normal_(module.weight, std=0.02)
        if module.padding_idx is not None:
            with torch.no_grad():
                module.weight[module.padding_idx].fill_(0)
        return

    if isinstance(module, nn.Conv2d):
        trunc_normal_(module.weight, std=0.02)
        if module.bias is not None:
            nn.init.zeros_(module.bias)
        return

    if isinstance(module, RMSNorm):
        nn.init.ones_(module.weight)
        return

    if isinstance(module, nn.LayerNorm):
        if module.weight is not None:
            nn.init.ones_(module.weight)
        if module.bias is not None:
            nn.init.zeros_(module.bias)
        return

    if isinstance(module, nn.MultiheadAttention):
        if getattr(module, 'in_proj_weight', None) is not None:
            trunc_normal_(module.in_proj_weight, std=0.02)
        else:
            if getattr(module, 'q_proj_weight', None) is not None:
                trunc_normal_(module.q_proj_weight, std=0.02)
            if getattr(module, 'k_proj_weight', None) is not None:
                trunc_normal_(module.k_proj_weight, std=0.02)
            if getattr(module, 'v_proj_weight', None) is not None:
                trunc_normal_(module.v_proj_weight, std=0.02)

        if getattr(module, 'in_proj_bias', None) is not None:
            nn.init.zeros_(module.in_proj_bias)
        if getattr(module, 'out_proj', None) is not None:
            trunc_normal_(module.out_proj.weight, std=0.02)
            if module.out_proj.bias is not None:
                nn.init.zeros_(module.out_proj.bias)
        if getattr(module, 'bias_k', None) is not None:
            nn.init.zeros_(module.bias_k)
        if getattr(module, 'bias_v', None) is not None:
            nn.init.zeros_(module.bias_v)
        return

# ------------------------------------------------------------------------------------
# 1. 核心模块：HyperConnection (完全修正的 mHC 版本)
# ------------------------------------------------------------------------------------

class HyperConnection(nn.Module):
    """
    Hyper-Connection 模块 (mHC版本).
    
    该模块取代了传统的残差连接，包含宽度连接（width connection）和
    深度连接（depth connection）两个步骤。
    
    可以选择使用动态模式（DHC），其中连接权重是根据输入动态生成的。
    mHC 升级核心：
    1. 对 H_pre 和 H_post 应用非负约束 (Sigmoid)
    2. 对 H_res 应用 Sinkhorn-Knopp 投影至双随机流形
    3. 动态映射输入采用 Flattening 而非 Mean
    4. 最终输出采用 Mean 聚合而非 Sum
    """
    def __init__(self, dim: int, rate: int, layer_id: int, dynamic: bool = True, device=None):
        super().__init__()
        self.dim = dim
        self.rate = rate
        self.layer_id = layer_id
        self.dynamic = dynamic
        
        # --- 静态映射初始化 ---
        # 论文建议：静态映射在初始化时应接近恒等映射或均匀分布
        # 对于 H_res: 单位矩阵是恒等映射的初始化
        init_H_res = torch.eye(rate, device=device)
        # 对于 H_pre: [1, 0, 0, ..., 0] 对应保留第0个流作为层输入
        init_H_pre = torch.zeros(rate, 1, device=device)
        init_H_pre[0, 0] = 1.0
        # 拼接为 static_alpha: [rate, rate + 1]
        self.static_alpha = nn.Parameter(torch.cat([init_H_pre, init_H_res], dim=1))
        # 对于 H_post (beta): 初始化为均匀分布 [1/rate, 1/rate, ..., 1/rate]
        self.static_beta = nn.Parameter(torch.ones(rate, device=device) / rate)

        if self.dynamic:
            self.layer_norm = RMSNorm(dim)
            # --- 关键修正点1: 动态映射输入采用 Flattening (论文公式7) ---
            # 输入维度应为 rate * dim (Flattened)，以保留完整的上下文信息
            self.dynamic_alpha_fn = nn.Linear(rate * dim, rate * (rate + 1), bias=False)
            self.dynamic_beta_fn = nn.Linear(rate * dim, rate, bias=False)
            
            # 论文 A.1 提到 gating factor 初始化为小值 (0.01)
            self.dynamic_alpha_scale = nn.Parameter(torch.full((1,), 0.01))
            self.dynamic_beta_scale = nn.Parameter(torch.full((1,), 0.01))

    def width_connection(self, h: torch.Tensor):
        B, L, N, D = h.shape # [B, L, rate, dim]
        
        if self.dynamic:
            norm_h = self.layer_norm(h) # [B, L, N, D]
            # --- 关键修正点2: 按照论文公式(7)进行 Flatten ---
            agg_h = norm_h.view(B, L, -1) # [B, L, rate*dim]
            
            dyn_alpha = torch.tanh(self.dynamic_alpha_fn(agg_h)).view(B, L, self.rate, self.rate + 1)
            dyn_beta = self.dynamic_beta_fn(agg_h).view(B, L, self.rate)
            
            # 应用 gating scale 并与静态部分相加
            alpha = self.static_alpha + dyn_alpha * self.dynamic_alpha_scale
            beta = self.static_beta + dyn_beta * self.dynamic_beta_scale
        else:
            alpha = self.static_alpha.expand(B, L, -1, -1)
            beta = self.static_beta.expand(B, L, -1)

        # --- mHC 核心约束开始 ---
        # 拆分 alpha: [B, L, rate, rate+1] -> H_pre_raw [B, L, rate, 1], H_res_raw [B, L, rate, rate]
        H_pre_raw = alpha[..., :1]      # [B, L, rate, 1]
        H_res_raw = alpha[..., 1:]      # [B, L, rate, rate]
        
        # --- 关键修正点3: H_pre 的非负约束 (论文公式8) ---
        H_pre = torch.sigmoid(H_pre_raw)
        
        # --- 关键修正点4: H_res 的 Sinkhorn 投影至双随机流形 ---
        # 注意：sinkhorn_knopp 内部通常包含 exp，所以输入不需要提前 exp
        # 但论文公式(9)确实写为 M(0) = exp(H~_res)
        # 我们的 sinkhorn_knopp 实现会处理这个 exp
        H_res = sinkhorn_knopp(H_res_raw, num_iter=20, epsilon=1e-12)
        
        # --- 关键修正点5: H_post (beta) 的非负约束 (论文公式8) ---
        # 论文公式(8)明确指出 H_post = 2 * sigmoid(~H_post)
        beta_constrained = 2.0 * torch.sigmoid(beta)
        # --- mHC 核心约束结束 ---

        # 应用 H_pre 和 H_res
        # h: [B, L, rate, dim]
        # h_for_layer: H_pre^T @ h -> [B, L, 1, dim]
        h_for_layer = torch.matmul(H_pre.transpose(-2, -1), h)
        # h_res_flow: H_res^T @ h -> [B, L, rate, dim]
        h_res_flow = torch.matmul(H_res.transpose(-2, -1), h)
        
        # 拼接: mix_h[..., 0, :] 是给 Layer F 的输入，mix_h[..., 1:, :] 是残差流
        mix_h = torch.cat([h_for_layer, h_res_flow], dim=-2) # [B, L, rate+1, dim]
        
        return mix_h, beta_constrained

    def depth_connection(self, mix_h: torch.Tensor, h_o: torch.Tensor, beta: torch.Tensor) -> torch.Tensor:
        # mix_h: [B, L, rate+1, dim]
        h_prime = mix_h[..., 1:, :] # [B, L, rate, dim] - 残差流部分
        # h_o: Layer F 的输出 [B, L, dim]
        # 对应论文公式(3): x^{l+1} = H_res^l x^l + (H_post^l)^T F(...)
        # h_o_weighted: (H_post^l)^T F(...) -> [B, L, rate, dim]
        h_o_weighted = torch.einsum('bld,bln->blnd', h_o, beta)
        return h_prime + h_o_weighted

# ------------------------------------------------------------------------------------
# 2. 文本模型构建块 
# ------------------------------------------------------------------------------------

class FeedForward(nn.Module):
    def __init__(self, dim: int, hidden_dim: int):
        super().__init__()
        self.net = nn.Sequential(nn.Linear(dim, hidden_dim), nn.GELU(), nn.Linear(hidden_dim, dim))
    def forward(self, x):
        return self.net(x)

class HyperConnectionBlock(nn.Module):
    def __init__(self, dim: int, n_heads: int, rate: int, layer_id: int, dropout: float = 0.1):
        super().__init__()
        # 使用 RMSNorm 替换原有的 LayerNorm，实现 Pre-Norm 结构
        self.attn_norm = RMSNorm(dim)
        self.ffn_norm = RMSNorm(dim)
        self.attention = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)
        self.ffn = FeedForward(dim, dim * 4)
        self.attn_hc = HyperConnection(dim, rate, layer_id, dynamic=True)
        self.ffn_hc = HyperConnection(dim, rate, layer_id, dynamic=True)
        self.attn_dropout = nn.Dropout(dropout)
        self.ffn_dropout = nn.Dropout(dropout)

    def forward(self, h: torch.Tensor, mask=None) -> torch.Tensor:
        mix_h_attn, beta_attn = self.attn_hc.width_connection(h)
        h_in_attn = self.attn_norm(mix_h_attn[..., 0, :])
        attn_output, _ = self.attention(h_in_attn, h_in_attn, h_in_attn, attn_mask=mask)
        h = self.attn_hc.depth_connection(mix_h_attn, self.attn_dropout(attn_output), beta_attn)
        mix_h_ffn, beta_ffn = self.ffn_hc.width_connection(h)
        h_in_ffn = self.ffn_norm(mix_h_ffn[..., 0, :])
        ffn_output = self.ffn(h_in_ffn)
        h = self.ffn_hc.depth_connection(mix_h_ffn, self.ffn_dropout(ffn_output), beta_ffn)
        return h

"""文本模型块：TextHyperConnectionBlock，使用 nn.MultiheadAttention"""
class TextHyperConnectionBlock(nn.Module):
    def __init__(self, dim: int, n_heads: int, rate: int, layer_id: int, dropout: float = 0.1):
        super().__init__()
        self.attn_norm = RMSNorm(dim)
        self.ffn_norm = RMSNorm(dim)
        self.attention = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)
        self.ffn = FeedForward(dim, dim * 4)
        self.attn_hc = HyperConnection(dim, rate, layer_id, dynamic=True)
        self.ffn_hc = HyperConnection(dim, rate, layer_id, dynamic=True)
        self.attn_dropout = nn.Dropout(dropout)
        self.ffn_dropout = nn.Dropout(dropout)

    def forward(self, h: torch.Tensor, mask=None) -> torch.Tensor:
        mix_h_attn, beta_attn = self.attn_hc.width_connection(h)
        h_in_attn = self.attn_norm(mix_h_attn[..., 0, :])
        attn_output, _ = self.attention(h_in_attn, h_in_attn, h_in_attn, attn_mask=mask)
        h = self.attn_hc.depth_connection(mix_h_attn, self.attn_dropout(attn_output), beta_attn)
        mix_h_ffn, beta_ffn = self.ffn_hc.width_connection(h)
        h_in_ffn = self.ffn_norm(mix_h_ffn[..., 0, :])
        ffn_output = self.ffn(h_in_ffn)
        h = self.ffn_hc.depth_connection(mix_h_ffn, self.ffn_dropout(ffn_output), beta_ffn)
        return h

# ------------------------------------------------------------------------------------
# 3. 文本模型
# ------------------------------------------------------------------------------------

class HyperConnectionTransformer(nn.Module):
    def __init__(self, vocab_size: int, max_len: int, dim: int, 
        n_layers: int, n_heads: int, rate: int, dropout: float = 0.1, drop_path: float = 0.0,
        return_hidden: bool = False):
        super().__init__()
        if dim % 2 != 0:
            raise ValueError(f"dim must be even for SinusoidalPositionEncoding, got {dim}")
        self.expansion_rate = rate
        self.token_embedding = nn.Embedding(vocab_size, dim)
        self.pos_encoding = SinusoidalPositionEncoding(d_model=dim, max_len=max_len)
        self.emb_dropout = nn.Dropout(dropout)
        self.max_len = max_len
        self.return_hidden = return_hidden

        self.layers = nn.ModuleList([
            TextHyperConnectionBlock(
                dim, n_heads, rate, layer_id, dropout
            ) for layer_id in range(n_layers)
        ])
        if n_layers > 0 and drop_path > 0.0:
            dpr = torch.linspace(0, drop_path, n_layers).tolist()
        else:
            dpr = [0.0 for _ in range(n_layers)]
        self.drop_paths = nn.ModuleList([
            DropPath(dpr[layer_id]) if dpr[layer_id] > 0.0 else nn.Identity()
            for layer_id in range(n_layers)
        ])
        self.final_norm = RMSNorm(dim)  # 替换 nn.LayerNorm(dim)
        self.lm_head = nn.Linear(dim, vocab_size) if not return_hidden else nn.Identity()
        self.apply(init_transformer_weights)

    def forward(self, idx: torch.Tensor, mask=None):
        B, L = idx.shape; device = idx.device
        tok_emb = self.token_embedding(idx)
        positions = torch.arange(0, L, device=device, dtype=torch.float32).unsqueeze(0)
        pos_emb = self.pos_encoding(positions).to(dtype=tok_emb.dtype)
        h = self.emb_dropout(tok_emb + pos_emb)
        H = h.unsqueeze(2).repeat(1, 1, self.expansion_rate, 1)
        for layer, dp in zip(self.layers, self.drop_paths):
            H = dp(layer(H, mask=mask))
        h_final = H.mean(dim=2)
        h_final = self.final_norm(h_final)
        logits = self.lm_head(h_final)
        return logits

# ------------------------------------------------------------------------------------
# 5. 图像模型构建块
# ------------------------------------------------------------------------------------

class ImageHyperConnectionBlock(nn.Module):
    def __init__(self, dim: int, n_heads: int, rate: int, layer_id: int, dropout: float = 0.1):
        super().__init__()
        self.attn_norm = RMSNorm(dim)
        self.ffn_norm = RMSNorm(dim)
        self.attention = nn.MultiheadAttention(dim, n_heads, dropout=dropout, batch_first=True)
        self.ffn = FeedForward(dim, dim * 4)
        self.attn_hc = HyperConnection(dim, rate, layer_id, dynamic=True)
        self.ffn_hc = HyperConnection(dim, rate, layer_id, dynamic=True)
        self.attn_dropout = nn.Dropout(dropout)
        self.ffn_dropout = nn.Dropout(dropout)

    def forward(self, h: torch.Tensor, mask=None) -> torch.Tensor:
        mix_h_attn, beta_attn = self.attn_hc.width_connection(h)
        h_in_attn = self.attn_norm(mix_h_attn[..., 0, :])
        attn_output, _ = self.attention(h_in_attn, h_in_attn, h_in_attn, attn_mask=mask)
        h = self.attn_hc.depth_connection(mix_h_attn, self.attn_dropout(attn_output), beta_attn)
        mix_h_ffn, beta_ffn = self.ffn_hc.width_connection(h)
        h_in_ffn = self.ffn_norm(mix_h_ffn[..., 0, :])
        ffn_output = self.ffn(h_in_ffn)
        h = self.ffn_hc.depth_connection(mix_h_ffn, self.ffn_dropout(ffn_output), beta_ffn)
        return h

# ------------------------------------------------------------------------------------
# 6. 图像模型 
# ------------------------------------------------------------------------------------

class ImageHyperConnectionTransformer(nn.Module):
    def __init__(self, image_size: int, patch_size: int, in_channels: int, num_classes: int, 
                 dim: int, n_layers: int, n_heads: int, rate: int, dropout: float = 0.1, drop_path: float = 0,
                 pool_size=4, mask_ratio=0.1):
        super().__init__()
        if dim % 2 != 0:
            raise ValueError(f"dim must be even for SinusoidalPositionEncoding, got {dim}")
        if type(image_size)==int: image_size = (image_size, image_size)
        if type(patch_size)==int: patch_size = (patch_size, patch_size)
        if type(pool_size)==int: pool_size = (pool_size, pool_size)
        self.expansion_rate = rate
        self.patch_size = patch_size
        self.width = image_size[1] // patch_size[1]
        self.height = image_size[0] // patch_size[0]
        self.num_patches = self.width * self.height

        pos_dim = dim // 2
        self.pos_y = SinusoidalPositionEncoding(d_model=pos_dim, max_len=self.height)
        self.pos_x = SinusoidalPositionEncoding(d_model=pos_dim, max_len=self.width)
        pos_y = torch.arange(self.height, dtype=torch.float32).unsqueeze(1).repeat(1, self.width)
        pos_x = torch.arange(self.width, dtype=torch.float32).unsqueeze(0).repeat(self.height, 1)
        pos_y = pos_y.flatten().unsqueeze(0)
        pos_x = pos_x.flatten().unsqueeze(0)
        pos_embed = torch.cat([self.pos_y(pos_y), self.pos_x(pos_x)], dim=-1)
        self.register_buffer('pos_embed', pos_embed, persistent=False)

        self.patch_embed = nn.Conv2d(in_channels, dim, kernel_size=patch_size, stride=patch_size)
        self.emb_dropout = nn.Dropout(dropout)

        self.layers = nn.ModuleList([
            ImageHyperConnectionBlock(
                dim, n_heads, rate, layer_id, dropout
            ) for layer_id in range(n_layers)])

        if n_layers > 0 and drop_path > 0:
            dpr = torch.linspace(0, drop_path, n_layers).tolist()
        else:
            dpr = [0.0 for _ in range(n_layers)]
        self.drop_paths = nn.ModuleList([
            DropPath(dpr[layer_id]) if dpr[layer_id] > 0.0 else nn.Identity()
            for layer_id in range(n_layers)
        ])
        self.final_norm = RMSNorm(dim)
        self.classifier = nn.Linear(dim*pool_size[0]*pool_size[1], num_classes)
        self.pool_size = pool_size
        self.mask_ratio = mask_ratio
        self.apply(init_transformer_weights)
    def random_masking(self, x, mask_ratio=0.1):
        """
        Perform per-sample random masking by per-sample shuffling.
        Per-sample shuffling is done by argsort random noise.
        x: [N, L, D], sequence
        """
        N, L, D = x.size()  # batch, length, dim
        len_keep = int(L * (1 - mask_ratio))

        noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]

        # sort noise for each sample
        # ascend: small is keep, large is remove
        ids_shuffle = torch.argsort(noise, dim=1)
        ids_restore = torch.argsort(ids_shuffle, dim=1)

        # keep the first subset
        ids_keep = ids_shuffle[:, :len_keep]
        x_masked = torch.gather(
            x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))

        # generate the binary mask: 0 is keep, 1 is remove
        mask = torch.ones([N, L], device=x.device)
        mask[:, :len_keep] = 0
        # unshuffle to get the binary mask
        mask = torch.gather(mask, dim=1, index=ids_restore)

        return x_masked, mask, ids_restore
    def forward(self, x: torch.Tensor, return_features=False):
        B = x.shape[0]
        x = self.patch_embed(x).flatten(2).transpose(1, 2)
        x = x + self.pos_embed.to(device=x.device, dtype=x.dtype)
        x = self.emb_dropout(x)
        B, L, C = x.shape
        Y = []
        ids_restore = None
        if self.training and self.mask_ratio > 0:
            x, _, ids_restore = self.random_masking(x)
            B, L, C = x.shape
        H = x.unsqueeze(2).repeat(1, 1, self.expansion_rate, 1)
        for layer, dp in zip(self.layers, self.drop_paths):
            H = dp(layer(H))
            y = H.mean(dim=2).permute(0, 2, 1).contiguous()  # (B, C, L_keep or L)
            if self.mask_ratio == 0 or not self.training or ids_restore is None:
                Y.append(y.view(B, C, self.width, self.height))
            else:
                # 重建被 mask 前的 full-length token 序列，并填充到对应位置
                len_keep = y.shape[-1]
                L_full = self.num_patches
                ids_shuffle = torch.argsort(ids_restore, dim=1)          # (B, L_full)
                ids_keep = ids_shuffle[:, :len_keep]                      # (B, len_keep)
                y_full = torch.zeros(B, C, L_full, device=y.device, dtype=y.dtype)
                y_full.scatter_(2, ids_keep.unsqueeze(1).expand(-1, C, -1), y)
                Y.append(y_full.view(B, C, self.width, self.height))
        
        # 【设计选择】对最终超隐藏状态取平均，这在视觉任务中很常见
        h_final = H.mean(dim=2)  # (B, L_keep or L_full, C)
        # 如果使用了 masking，则需要先用 ids_restore 还原到 full-length，再做空间 reshape
        if self.training and self.mask_ratio > 0 and ids_restore is not None:
            y_tokens = h_final.permute(0, 2, 1).contiguous()  # (B, C, L_keep)
            len_keep = y_tokens.shape[-1]
            L_full = self.num_patches
            ids_shuffle = torch.argsort(ids_restore, dim=1)      # (B, L_full)
            ids_keep = ids_shuffle[:, :len_keep]                  # (B, len_keep)
            y_full = torch.zeros(B, C, L_full, device=y_tokens.device, dtype=y_tokens.dtype)
            y_full.scatter_(2, ids_keep.unsqueeze(1).expand(-1, C, -1), y_tokens)
            h_final = y_full.permute(0, 2, 1).contiguous()        # (B, L_full, C)

        h_final = self.final_norm(h_final)
        
        # 使用全局平均池化进行分类
        h_pooled = h_final.permute(0, 2, 1).contiguous().view(B, C, self.width, self.height)
        h_pooled = F.interpolate(h_pooled, (self.pool_size[0], self.pool_size[1]))
        h_pooled = h_pooled.view(B, C*self.pool_size[0] * self.pool_size[1])
        logits = self.classifier(h_pooled)
        Y.append(logits)
        if return_features: return Y
        return logits

# ------------------------------------------------------------------------------------
# 7. 解码器模型
# ------------------------------------------------------------------------------------

class HyperConnectionDecodeTransformer(nn.Module):
    """
    解码器结构的 HyperConnection Transformer（自回归）。
    - 不包含 KV cache（简单实现）。
    - 支持 past_len 参数来表示已有前缀长度，从而构建正确的因果掩码。
    """
    def __init__(self, vocab_size: int, max_len: int, dim: int, n_layers: int, 
        n_heads: int, rate: int, dropout: float = 0.1):
        super().__init__()
        if dim % 2 != 0:
            raise ValueError(f"dim must be even for SinusoidalPositionEncoding, got {dim}")
        self.expansion_rate = rate
        self.token_embedding = nn.Embedding(vocab_size, dim)
        self.pos_encoding = SinusoidalPositionEncoding(d_model=dim, max_len=max_len)
        self.emb_dropout = nn.Dropout(dropout)
        self.max_len = max_len

        self.layers = nn.ModuleList([
            TextHyperConnectionBlock(
                dim, n_heads, rate, layer_id, dropout
            ) for layer_id in range(n_layers)
        ])
        self.final_norm = RMSNorm(dim)
        self.lm_head = nn.Linear(dim, vocab_size)
        self.apply(init_transformer_weights)

    def _build_causal_mask(self, seq_len: int, past_len: int, device: torch.device):
        """
        构建自回归因果掩码：返回形状 (seq_len, total_k) 的布尔掩码，True 表示允许（attend），False 表示屏蔽。
        total_k = past_len + seq_len
        对于查询位置 i (0-based), 允许访问所有 past positions (j < past_len) 以及当前段中 j <= past_len + i
        """
        total_k = past_len + seq_len
        q_idx = torch.arange(seq_len, device=device).unsqueeze(1)  # (seq_len, 1)
        k_idx = torch.arange(total_k, device=device).unsqueeze(0)  # (1, total_k)
        allowed = (k_idx < past_len) | (k_idx <= (past_len + q_idx))
        # Convert to float mask with 1/0 for compatibility where code checks mask==0
        return allowed

    def forward(self, input_ids: torch.Tensor, past_len: int = 0, mask: torch.Tensor = None):
        """
        Args:
            input_ids: (batch, seq_len)
            past_len: int, 表示已存在的前缀长度（用于 causal mask）
            mask: 额外的注意力 mask，优先级叠加在因果掩码上
        Returns:
            logits: (batch, seq_len, vocab_size)
        """
        B, L = input_ids.shape
        device = input_ids.device
        if past_len + L > self.max_len:
            raise ValueError(f"Input length + past_len ({past_len + L}) exceeds max_len ({self.max_len})")

        tok_emb = self.token_embedding(input_ids)
        positions = torch.arange(past_len, past_len + L, device=device, dtype=torch.float32).unsqueeze(0)
        pos_emb = self.pos_encoding(positions).to(dtype=tok_emb.dtype)
        h = self.emb_dropout(tok_emb + pos_emb)
        H = h.unsqueeze(2).repeat(1, 1, self.expansion_rate, 1)

        causal_mask = torch.triu(
            torch.ones(L, L, device=device, dtype=torch.bool),
            diagonal=1,
        )
        attn_mask = causal_mask

        for layer in self.layers:
            H = layer(H, mask=attn_mask)
        h_final = H.mean(dim=2)
        h_final = self.final_norm(h_final)
        logits = self.lm_head(h_final)
        return logits

# ------------------------------------------------------------------------------------
# 9. 测试用例
# ------------------------------------------------------------------------------------
if __name__ == '__main__':
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用设备: {device}")
    
    # --- 图像模型测试 ---
    img_model = ImageHyperConnectionTransformer(
        image_size=224, patch_size=16, in_channels=3, num_classes=10,
        dim=512, n_layers=6, n_heads=8, rate=4, dropout=0.1
    )
    img_model = img_model.to(device)
    
    print("\n" + "=" * 60)
    print("Image Hyper-Connections Transformer 模型测试")
    print("=" * 60)
    
    # 运行模型
    dummy_img = torch.randn(4, 3, 224, 224, device=device)
    print(f"输入图像形状: {dummy_img.shape}")
    logits = img_model(dummy_img)
    assert logits.shape == (4, 10), "图像模型输出形状错误！"
    print(f"输出 Logits 形状: {logits.shape} (测试通过)")
    loss = logits.sum(); loss.backward()
    print("图像模型前向及反向传播测试通过。")
    print("-" * 60)

    # --- 文本模型测试 ---
    text_model = HyperConnectionTransformer(
        vocab_size=10000, max_len=512, dim=512, n_layers=6,
        n_heads=8, rate=4, dropout=0.1
    )
    text_model = text_model.to(device)
    
    print("\nHyper-Connections Transformer (文本) 模型测试")
    print("=" * 60)
    
    # 运行模型
    dummy_text = torch.randint(0, 10000, (4, 128), device=device)
    print(f"输入文本形状: {dummy_text.shape}")
    logits = text_model(dummy_text)
    assert logits.shape == (4, 128, 10000), "文本模型输出形状错误！"
    print(f"输出 Logits 形状: {logits.shape} (测试通过)")
    loss = logits.sum(); loss.backward()
    print("文本模型前向及反向传播测试通过。")
    
    print("\n" + "=" * 60)
    print("内存使用测试")
    print("=" * 60)
    
    # 测试模型内存占用
    def get_model_size(model):
        param_size = 0
        buffer_size = 0
        for param in model.parameters():
            param_size += param.nelement() * param.element_size()
        for buffer in model.buffers():
            buffer_size += buffer.nelement() * buffer.element_size()
        return param_size / 1024 / 1024, buffer_size / 1024 / 1024  # 转换为 MB
    
    param_size, buffer_size = get_model_size(img_model)
    print(f"图像模型参数大小: {param_size:.2f} MB")
    print(f"图像模型 Buffer 大小: {buffer_size:.2f} MB")
    
    param_size, buffer_size = get_model_size(text_model)
    print(f"文本模型参数大小: {param_size:.2f} MB")
    print(f"文本模型 Buffer 大小: {buffer_size:.2f} MB")
    print("=" * 60)

    # --- 解码器模型测试 ---
    dec_model = HyperConnectionDecodeTransformer(
        vocab_size=10000, max_len=512, dim=512, n_layers=6,
        n_heads=8, rate=4, dropout=0.1
    )
    dec_model = dec_model.to(device)
    
    print("\nHyper-Connections Decode Transformer (解码器) 模型测试")
    print("=" * 60)
    
    # 运行模型
    dummy_input = torch.randint(0, 10000, (4, 128), device=device)
    print(f"输入序列形状: {dummy_input.shape}")
    logits = dec_model(dummy_input)
    assert logits.shape == (4, 128, 10000), "解码器模型输出形状错误！"
    print(f"输出 Logits 形状: {logits.shape} (测试通过)")
    loss = logits.sum(); loss.backward()
    print("解码器模型前向及反向传播测试通过。")
    print("=" * 60)

